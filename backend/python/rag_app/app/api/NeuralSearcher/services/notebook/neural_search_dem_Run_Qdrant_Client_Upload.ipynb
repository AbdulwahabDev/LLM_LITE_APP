{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Qdrant in Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chick if Qdrant Runing ...\n",
    "http://localhost:6333/dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import client library\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdulwahabmac/Desktop/MyFiles/Projects/Training/Tuwaiq/LLM_lite_app/.env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\n",
    "    \"all-MiniLM-L6-v2\", device=\"cpu\"\n",
    ")  # or device=\"cpu\" if you don't have a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection startups Created !!\n"
     ]
    }
   ],
   "source": [
    "collection_name = 'startups'\n",
    "\n",
    "if not client.collection_exists(collection_name):\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(\n",
    "                                    size=model.get_sentence_embedding_dimension(),\n",
    "                                    distance=Distance.COSINE\n",
    "                                   ),\n",
    "    )\n",
    "    print(f\"collection {collection_name} Created !!\")\n",
    "else:\n",
    "    print(f\"collection {collection_name} exists !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = open(\"./startups_demo.json\")\n",
    "payload = list(map(json.loads, fd))\n",
    "\n",
    "# Load all vectors into memory, numpy array works as iterable for itself.\n",
    "# Other option would be to use Mmap, if you don't want to load all data into RAM\n",
    "vectors = np.load(\"./startup_vectors.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SaferCodes',\n",
       " 'images': 'https://safer.codes/img/brand/logo-icon.png',\n",
       " 'alt': 'SaferCodes Logo QR codes generator system forms for COVID-19',\n",
       " 'description': 'QR codes systems for COVID-19.\\nSimple tools for bars, restaurants, offices, and other small proximity businesses.',\n",
       " 'link': 'https://safer.codes',\n",
       " 'city': 'Chicago'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40474"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(payload_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40474"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40474/40474 [00:42<00:00, 959.08it/s]\n"
     ]
    }
   ],
   "source": [
    "client.upload_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors=vectors,\n",
    "    payload=payload,\n",
    "    ids=tqdm(range(len(payload))),\n",
    "    batch_size=256,  # How many vectors will be uploaded in a single request?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
